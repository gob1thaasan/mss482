{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6027a45f-d731-4ff1-8527-b4db811bb2f9",
   "metadata": {
    "id": "fRuRcAt3F_wS"
   },
   "source": [
    "\n",
    "# MSS482 - GRAPHING TECHNOLOGY IN MATHEMATICS AND SCIENCE\n",
    "\n",
    "**SEMESTER 1 2023/2024**\n",
    "\n",
    "\n",
    ">R.U.Gobithaasan (2023). School of Mathematical Sciences, Universiti Sains Malaysia.\n",
    "[Official Website](https://math.usm.my/academic-profile/705-gobithaasan-rudrusamy) \n",
    "\n",
    "\n",
    "<p align=\"center\">\n",
    "     © 2023 R.U. Gobithaasan All Rights Reserved.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9069ae-3da6-41b9-88f1-cb26da15581c",
   "metadata": {},
   "source": [
    "# Analysing more than one variable\n",
    "- https://www.pythonfordatascience.org/independent-samples-t-test-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db82e975-28ad-49ac-9960-82538ce11fd0",
   "metadata": {},
   "source": [
    "3.1 Anlyzing dataset with <br>\n",
    "    a) Continuous features <br>\n",
    "    b) Categorical features <br>\n",
    "\n",
    "3.2. t-Test <br>\n",
    "    a) Independent Samples t-test <br>\n",
    "    b) Paired Samples t-test <br>\n",
    "\n",
    "\n",
    "3.3 Correlation\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14ade7d",
   "metadata": {},
   "source": [
    "### requirements\n",
    "\n",
    "> Install the following: `!python -m pip install pandas`\n",
    "1. pandas\n",
    "2. researchpy\n",
    "3. statsmodels\n",
    "4. matplotlib\n",
    "5. seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31aad3b9-a5ff-430c-bda0-922d8e3de635",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Dataset: Online Dataset sources\n",
    "\n",
    "**Online Sources:** \n",
    "- Google Dataset Search: https://datasetsearch.research.google.com/ \n",
    "- Kaggle: https://www.kaggle.com/datasets \n",
    "- UCI Machine Learning Repository: https://archive.ics.uci.edu/ml/datasets.php \n",
    "- Earth Data: https://www.earthdata.nasa.gov/\n",
    "- Scikit Dataset: https://scikit-learn.org/stable/datasets.html\n",
    "- https://github.com/gob1thaasan/Data-sets \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0cf54e",
   "metadata": {},
   "source": [
    "### Tips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba723a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Magic command to display Matplotlib plots inline :https://ipython.readthedocs.io/en/stable/interactive/magics.html\n",
    "%matplotlib inline\n",
    "# To ignore warnings, use the following code to make the display more attractive.\n",
    "# Import seaborn and matplotlib.\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa413f35",
   "metadata": {},
   "source": [
    "# Analyzing Continuous & Categorical Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d8fb3a",
   "metadata": {},
   "source": [
    "## Numeric Data\n",
    "> Numeric data is information that can be expressed as a number: Can be continuous or discrete.\n",
    "\n",
    "Continuous data is data that can take any value. Height, weight, temperature and length are all examples of continuous data. Some continuous data will change over time; the weight of a baby in its first year or the temperature in a room throughout the day. This data is best shown on a line graph as this type of graph can show how the data changes over a given period of time. Other continuous data, such as the heights of a group of children on one particular day, is often grouped into categories to make it easier to interpret.\n",
    "\n",
    "Discrete data is information that can only take certain values. These values don’t have to be whole numbers. For example, the number of hospital visit to schedule for the week and the number of students attending a lecture each day. This type of data is often represented using tally charts, bar charts or pie charts.\n",
    "\n",
    "\n",
    "---\n",
    "## Categorical Data\n",
    "- https://www.datacamp.com/tutorial/categorical-data\n",
    "\n",
    "Data that can be categorized but lacks an inherent hierarchy or order is known as categorical data. In other words, there is no mathematical connection between the categories. A person's gender (male/female), eye color (blue, green, brown, etc.), type of vehicle they drive (sedan, SUV, truck, etc.), or the kind of fruit they consume (apple, banana, orange, etc.) are examples of categorical data.\n",
    "\n",
    "- In simple terms, categorical data is information that can be put into categories.\n",
    "- Since the majority of machine learning algorithms are created to operate with numerical data, categorical data is handled differently from numerical data in this field. \n",
    "- Before categorical data can be utilized as input to a machine learning model, it must first be transformed into numerical data. \n",
    "- This process of converting categorical data into numeric representation is known as encoding.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e26ba98",
   "metadata": {},
   "source": [
    "### Univariate: Weight of a group (toy example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbfe909",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "x = np.array([148, 154, 158, 160, 161, 162, 166, 170, 182, 195, 236])\n",
    "\n",
    "# Plotting distribution plot (histogram + kernel density estimation) on the second subplot\n",
    "sns.histplot(x, kde=True, color='salmon')\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a98c584",
   "metadata": {},
   "source": [
    "- Kernel Density Estimation (KDE) is a non-parametric method used for estimating the probability density function (PDF) of a continuous random variable. It's a technique to visualize the distribution of data in a smoothed continuous form.\n",
    "- In simple terms, KDE provides a smooth curve that approximates the shape of the underlying probability distribution of a dataset. It estimates the density function by placing a kernel (a smooth, symmetric function such as a Gaussian or Epanechnikov kernel) at each data point and summing up these kernels to create a smooth curve that represents the overall distribution of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997b3492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Seaborn to create the boxplot\n",
    "sns.boxplot(data=x)  # You can specify your own color palette\n",
    "\n",
    "# Setting labels and title\n",
    "plt.xlabel('Categories')\n",
    "plt.ylabel('Values')\n",
    "plt.title('Boxplot Example for toy data')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc8e96e",
   "metadata": {},
   "source": [
    "#### Multivariate: Fictional blood-pressure data\n",
    "\n",
    "Multivariate analysis refers to the analysis of datasets involving more than one variable. It aims to understand the relationships between multiple variables simultaneously and uncover patterns, dependencies, and interactions among them.\n",
    "\n",
    "- There are various techniques and methods for multivariate analysis, each serving different purposes based on the nature of the data and the objective of the analysis. \n",
    "\n",
    "- When performing multivariate analysis, it's crucial to understand the assumptions of each technique and interpret the results accordingly. Additionally, visualization techniques like scatter plots, heatmap, and pair plots can aid in understanding relationships between multiple variables.\n",
    "\n",
    "- The choice of technique depends on the research question, the nature of the data, and the specific objectives of the analysis. Depending on your dataset and research objectives, you can select an appropriate multivariate analysis technique to derive insights and patterns from your data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff8118c",
   "metadata": {},
   "source": [
    "\n",
    "### Example: blood pressure of patients before and after treatment (taken from a book Stata 11 manual: https://www.stata-press.com/data/r11/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fc2c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/researchpy/Data-sets/master/blood_pressure.csv\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e89a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2c4cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06b94f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534e626d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Types of feature?</b>  Classify the features into continuous and categorical dataset\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3df8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sex'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50dec10",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_group = df['agegrp'].unique()\n",
    "print(age_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156d2c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['bp_before'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c4915d",
   "metadata": {},
   "source": [
    "- Blood pressure is an example of continuous data. Blood pressure can be measured to as many decimals as the measuring instrument allows. For example, although a typical blood pressure cuff does not provide decimal places, a digital blood pressure monitor (often used in hospital settings) may have the capacity to determine the blood pressure to 3 decimal places, and even more powerful blood pressure monitors may be developed that can read a patients blood pressure to 5 decimal places."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad36032",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Sampling:</b> Randomly choosing some samples from a population.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62acecef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9ad2f6",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis: Visualizatiton\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8da5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the plot style (e.g., 'ggplot', 'seaborn-dark', 'fivethirtyeight', etc.)\n",
    "'''\n",
    "'seaborn' - Seaborn-like style\n",
    "'ggplot' - Style similar to ggplot in R\n",
    "'fivethirtyeight' - Style similar to plots on FiveThirtyEight\n",
    "'classic' - Classic Matplotlib style\n",
    "'bmh' - Style from the Bayesian Methods for Hackers book\n",
    "'dark_background' - Dark background style\n",
    "'tableau-colorblind10' - Tableau colorblind 10 palette\n",
    "'Solarize_Light2' - Light background with strong colors\n",
    "'seaborn-dark-palette' - Seaborn dark palette\n",
    "'seaborn-whitegrid' - Seaborn style with white grid lines\n",
    "'''\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "df_gender = df.groupby('sex')\n",
    "df_gender.boxplot()\n",
    "df_gender.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0938a1",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Exercise:</b> Try plotting boxplot grouped by age group.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5290305d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6054da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# customizing dataframe for further analysis.\n",
    "df_male_after = df['bp_after'][df['sex'] == 'Male']\n",
    "df_female_after = df['bp_after'][df['sex'] == 'Female']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd0ba48",
   "metadata": {},
   "outputs": [],
   "source": [
    "after_treatment_gender_data = {'male': np.array(df_male_after), \n",
    "                          'female': np.array(df_female_after)}\n",
    "df_after_treatment_gender =pd.DataFrame(after_treatment_gender_data)\n",
    "df_after_treatment_gender.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664dbf26",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=df_after_treatment_gender)\n",
    "\n",
    "plt.title('Boxplot of blood pressure after treatment based on gender')\n",
    "plt.xlabel('gender')\n",
    "plt.ylabel('blood pressure')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48756d56",
   "metadata": {},
   "source": [
    "Seaborn offers a variety of color palettes that you can use for your plots. Here is a list of some of the named palettes available in Seaborn:\n",
    "\n",
    "- Sequential Color Palettes:\n",
    "'rocket'\n",
    "'mako'\n",
    "'flare'\n",
    "'crest'\n",
    "'cividis'\n",
    "'viridis'\n",
    "'plasma'\n",
    "'inferno'\n",
    "'magma'\n",
    "\n",
    "- Diverging Color Palettes:\n",
    "'coolwarm'\n",
    "'RdBu'\n",
    "'PuOr'\n",
    "'BrBG'\n",
    "'PiYG'\n",
    "'PRGn'\n",
    "\n",
    "- Qualitative Color Palettes:\n",
    "'pastel'\n",
    "'bright'\n",
    "'dark'\n",
    "'deep'\n",
    "'colorblind'\n",
    "'Set1', 'Set2', 'Set3'\n",
    "'tab10', 'tab20', 'tab20b', 'tab20c'\n",
    "\n",
    "- Other Palettes:\n",
    "'husl'\n",
    "'hls'\n",
    "'twilight'\n",
    "'twilight_shifted'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b57cb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting distribution plot (histogram + kernel density estimation) on the second subplot\n",
    "sns.histplot(df_male_after, kde=True, palette='mako')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94027474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting distribution plot (histogram + kernel density estimation) on the second subplot\n",
    "sns.histplot(df_female_after, kde=True, palette='bright')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5eb6c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting distribution plot (histogram + kernel density estimation) on the second subplot\n",
    "sns.histplot(df_after_treatment_gender, kde=True, palette='bright')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16245b9",
   "metadata": {},
   "source": [
    " <div class=\"alert alert-block alert-danger\">\n",
    "<b>What type of distribution does this feature possess?</b> Try plotting probability plot.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c752f6",
   "metadata": {},
   "source": [
    "A probability plot, also known as a Q-Q (quantile-quantile) plot, is a graphical method used to assess whether a dataset follows a particular theoretical distribution, such as the normal distribution.\n",
    "\n",
    "The main purpose of a probability plot is to visually compare the quantiles of a dataset against the quantiles of a theoretical distribution. If the data follows the theoretical distribution closely, the points on the plot will fall approximately along a straight line, indicating that the data fits that distribution well.\n",
    "\n",
    "For instance, when assessing normality using a Q-Q plot:\n",
    "\n",
    "- If the data points form a straight line, it indicates the data is normally distributed.\n",
    "- If the points deviate from a straight line, it suggests a departure from normality.\n",
    "\n",
    ">`probplot` optionally calculates a best-fit line for the data and plots the\n",
    "results using Matplotlib or a given plot function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07419873",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Using a custom color palette\n",
    "custom_palette = sns.color_palette(['#FF5733', '#33FF57', '#3357FF'])  # List of RGB/hex colors: https://www.color-hex.com/\n",
    "sns.set_palette(custom_palette)\n",
    "\n",
    "sampling_male= np.array(df['bp_after'][df['sex'] == 'Male'])\n",
    "\n",
    "normality_plot, stat = stats.probplot(sampling_male, plot= plt, rvalue= True,)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6583c0eb",
   "metadata": {},
   "source": [
    " <div class=\"alert alert-block alert-danger\">\n",
    "<b>What type of distribution does female samples possess?</b> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1a3368",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "194656d0",
   "metadata": {},
   "source": [
    " <div class=\"alert alert-block alert-danger\">\n",
    "<b>What type of distribution does the sampling difference between male and female possess?</b> Plot the probability plot and its distribution.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cbf94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Using a custom color palette\n",
    "custom_palette = sns.color_palette(['#FF5733', '#33FF57', '#3357FF'])  # List of RGB/hex colors: https://www.color-hex.com/\n",
    "sns.set_palette(custom_palette)\n",
    "\n",
    "sampling_difference = np.array(df['bp_after'][df['sex'] == 'Male'])- np.array(df['bp_after'][df['sex'] == 'Female'])\n",
    "\n",
    "normality_plot, stat = stats.probplot(sampling_difference, plot= plt, rvalue= True,)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a24af4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting distribution plot (histogram + kernel density estimation) on the second subplot\n",
    "sns.histplot(sampling_difference, kde=True, palette=custom_palette)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135303bb",
   "metadata": {},
   "source": [
    "> This shows our data is normalized, although, at two ends the data does not exactly fit the red line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1708a92f",
   "metadata": {},
   "source": [
    "Another method to check for the normality is to use the Shapiro-Wilk test.\n",
    "- The value of this statistic tends to be high (close to 1) for samples drawn from a normal distribution.\n",
    "- The null hypothesis of the Shapiro-Wilk test is that the data are normally distributed. \n",
    "- If the p-value resulting from the test is less than a chosen significance level (commonly 0.05), we reject the null hypothesis, concluding that the data do not follow a normal distribution.\n",
    "- If the p-value is “small” - that is, if there is a low probability of sampling data from a normally distributed population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2ee268",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.shapiro(sampling_difference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd24a211",
   "metadata": {},
   "source": [
    "Both the statistic and p-value are high, 98%  and 71% respectively, which means our residual data is normally distributed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee273695",
   "metadata": {},
   "source": [
    "---\n",
    "## More on Categorical Dataset\n",
    "- https://www.datacamp.com/tutorial/categorical-data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c40729",
   "metadata": {},
   "source": [
    " - This classic dataset contains the prices and other attributes of almost 54,000 diamonds. It's a great dataset for beginners learning to work with data analysis and visualization.\n",
    " https://www.kaggle.com/datasets/shivam2503/diamonds\n",
    "\n",
    " Below is a sample of the dataset and its the features:\n",
    "\n",
    "- price: price in US dollars (find the range)\n",
    "\n",
    "- carat: weight of the diamond (find the range)\n",
    "\n",
    "- cut: quality of the cut (find the categories)\n",
    "\n",
    "- color: diamond colour, from J (worst) to D (best)\n",
    "\n",
    "- clarity: a measurement of how clear the diamond is (I1 (worst), SI2, SI1, VS2, VS1, VVS2, VVS1, IF (best))\n",
    "\n",
    "- Symmetry (find the categories)\n",
    "\n",
    "- Report (find the categories)\n",
    "\n",
    "- Polish (find the categories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbf8f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv using pandas\n",
    "data = pd.read_csv('https://raw.githubusercontent.com/pycaret/pycaret/master/datasets/diamond.csv')\n",
    "\n",
    "# check the data types\n",
    "data.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59230169",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Types of feature?</b>  Classify the features into continuous and categorical dataset\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ef022d",
   "metadata": {},
   "source": [
    "- Well, all the columns in this example are categorical except for `Carat Weight` and `Price.` Let’s see if we are right about this by checking the default data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25e4c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# check the head of dataframe\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc413285",
   "metadata": {},
   "source": [
    "`value_counts()` is a function in the pandas library that returns the frequency of each unique value in a categorical data column. This function is useful when you want to get a quick understanding of the distribution of a categorical variable, such as the most common categories and their frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566c3c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv using pandas\n",
    "import pandas as pd\n",
    "data = pd.read_csv('https://raw.githubusercontent.com/pycaret/pycaret/master/datasets/diamond.csv')\n",
    "\n",
    "# check value counts of Cut column\n",
    "bar_data = data['Cut'].value_counts()\n",
    "bar_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb92418",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cut_counts = data['Cut'].value_counts()\n",
    "df_type_cut = pd.DataFrame({'cut type': list(cut_counts.index), 'count': list(cut_counts.values)})\n",
    "df_type_cut.plot.bar(x='cut type', y='count')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4387144",
   "metadata": {},
   "source": [
    "`groupby()` is a function in Pandas that allows you to group data by one or more columns and apply aggregate functions such as sum, mean, and count. This function is useful when you want to perform more complex analysis on categorical data, such as computing the average of a numeric variable for each category. Let’s see an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f9850f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying groupby() function to\n",
    "d_color = data.groupby('Color')\n",
    "# Let's print the first entries in all the groups formed.\n",
    "\n",
    "d_color.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2ef1f2",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Find the details of a particular group:</b>`get_group()`\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b363f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_color.get_group('D')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d0ee5d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bdfbb471",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Let's convert a categorical feature into numerical representation</b>: We can then carry out more computation & calculation for modelling and machine learning tasks.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef0bf27",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Cut']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef607c45",
   "metadata": {},
   "source": [
    "One- hot encoding is a process of representing categorical data as a set of binary values, where each category is mapped to a unique binary value. \n",
    "- In this representation, only one bit is set to 1, and the rest are set to 0, hence the name \"one hot.\" \n",
    "- This is commonly used in machine learning to convert categorical data into a format that algorithms can process.\n",
    "- The `pd.get_dummies() function in pandas performs one-hot encoding by converting the categorical variable ('Cut') into multiple binary columns representing each category. The new columns have binary values (0 or 1) indicating the presence of each category in the original data.\n",
    "- For example, we can perform one-hot encoding on categorical features using SKLearn, then train a basic machine learning model (Logistic Regression) using the encoded features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7dab3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply get_dummies function\n",
    "df_encoded = pd.get_dummies(data[\"Cut\"])\n",
    "df_encoded .tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a40d181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting one-hot encoded DataFrame to 0-1 array\n",
    "array_representation = df_encoded.values\n",
    "print(array_representation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a9c161",
   "metadata": {},
   "source": [
    "We will learn more on Analysis of Categorical Data in the last week of this course\n",
    "- https://ethanweed.github.io/pythonbook/05.01-chisquare.html \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1649a9a0",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Carry out similar tasks for iris dataset. Continue the code below.</b>\n",
    "</div>\n",
    "\n",
    "- Boxplot\n",
    "- Scatterplot\n",
    "- Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca32297",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#df = pd.read_csv(\"https://raw.githubusercontent.com/researchpy/Data-sets/master/blood_pressure.csv\")\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/Opensourcefordatascience/Data-sets/master/Iris_Data.csv\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a21bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb6429b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f3351d",
   "metadata": {},
   "source": [
    "# t tests\n",
    "- https://www.pythonfordatascience.org/parametric-assumptions-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c232bd63",
   "metadata": {},
   "source": [
    "**Parametric methods** in statistics refer to techniques or tests that assume a specific distribution for the population being studied. Typically, they assume that the data follow a known probability distribution (such as normal, exponential, binomial, etc.) with a fixed number of parameters.\n",
    "\n",
    "Some key points about parametric methods:\n",
    "\n",
    "- Assumption of Distribution: Parametric methods assume the underlying data follows a specific probability distribution.\n",
    "- Parameter Estimation: They involve estimating parameters (like mean, variance, etc.) from the data to describe the population.\n",
    "- Greater Statistical Power: When the assumptions hold, parametric methods tend to be more powerful (i.e., better at detecting true effects) than non-parametric methods for the same sample size.\n",
    "- Common Parametric Tests: Examples of parametric tests include **t-tests**, ANOVA (Analysis of Variance), linear regression, Pearson correlation, etc.\n",
    "- However, these methods are sensitive to departures from their underlying assumptions. If the data doesn’t follow the assumed distribution, the results from parametric tests might be unreliable. In such cases, non-parametric methods, which make fewer assumptions about the population distribution, might be more appropriate.\n",
    "\n",
    "Overall, parametric methods provide valuable tools for statistical analysis when their underlying assumptions are met, but it's crucial to verify these assumptions before relying solely on parametric techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582e0878",
   "metadata": {},
   "source": [
    "**Nonparametric methods** in statistics are techniques that do not rely on specific assumptions about the underlying probability distributions of the data. These methods are used when the data violate assumptions required by parametric methods or when the nature of the data doesn't fit well with assumptions of known distributions.\n",
    "\n",
    "Key aspects of non-parametric methods:\n",
    "\n",
    "- Distribution-Free Methods: Non-parametric methods don't assume a particular distribution for the data. They are more flexible and can handle data that doesn't conform to normality or other specific distributions.\n",
    "- Based on Ranks or Order Statistics: Instead of using the original data values, non-parametric methods often rely on the ranks or orderings of the data values, making them less sensitive to outliers or extreme values.\n",
    "- Less Statistical Power: Non-parametric methods might have lower statistical power compared to parametric methods, especially when the assumptions of parametric methods are met.\n",
    "- Types of Tests: Common non-parametric tests include the Mann-Whitney U test (an alternative to the independent samples t-test), Wilcoxon signed-rank test (for paired samples), Kruskal-Wallis test (an alternative to ANOVA), Spearman's rank correlation, and others.\n",
    "\n",
    "Non-parametric methods are useful in various scenarios:\n",
    "- When dealing with small sample sizes.\n",
    "- With ordinal or categorical data.\n",
    "- When data distribution significantly deviates from normality.\n",
    "- When assumptions of parametric tests are violated.\n",
    "\n",
    "While non-parametric methods offer flexibility, they might not be as efficient as parametric methods when data meet parametric assumptions. The choice between parametric and non-parametric methods often depends on the nature of the data and the context of the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6515cf",
   "metadata": {},
   "source": [
    "A **t test** is a statistical method used *to determine if there is a significant difference between the means of two groups*. It assesses whether the means of two sets of data are statistically different from each other, considering the variability within the data sets. Two types of t-tests:\n",
    "- **Independent Samples t-test** (Two distinct groups):\n",
    "\n",
    "Let's say you want to compare the average test scores of two different groups of students (Group A and Group B) to see if there's a significant difference in their performance. You collect data on test scores from both groups and conduct an independent samples t-test to determine if the mean scores between Group A and Group B are significantly different.\n",
    "\n",
    "- **Paired Samples t-test** (one group with different settings):\n",
    "\n",
    "Consider a study where you measure the blood pressure of the same group of individuals before and after a certain treatment. You want to find out if there's a significant change in their blood pressure after the treatment. You collect paired data (before and after measurements from the same individuals) and perform a paired samples t-test to compare the mean blood pressure before and after the treatment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d56de62",
   "metadata": {},
   "source": [
    "#### ASSUMPTION CHECK\n",
    "\n",
    ">Different t-tests have specific assumptions that should be met for the results to be valid and reliable:\n",
    "\n",
    "**Independent Samples t-test Assumptions:**\n",
    "\n",
    "1. **Independence**: The observations within each group must be independent of each other. Also, the two groups being compared must be independent.\n",
    "2. **Normality**: The data within each group should ideally follow a normal distribution. However, the t-test is robust to violations of normality for large sample sizes due to the Central Limit Theorem.\n",
    "\n",
    "                - We can use probability plot available in Scipy.stat to validate.\n",
    "                - We can use Shapiro-Wilk test. This can be completed using the `shapiro()` method from Scipy.stats\n",
    "\n",
    "3. **Homogeneity of Variance**: The variances in the two groups should be approximately equal. Violations of this assumption can affect the accuracy of the t-test. If group variances are very different, adjustments might be necessary.\n",
    "\n",
    "                - We can use Levene test. This can be completed using the `shapiro()` method from Scipy.stats.\n",
    "\n",
    "\n",
    "**Paired Samples t-test Assumptions:**\n",
    "1. **Dependent Samples**: The samples should be related or paired in some way (e.g., before and after measurements on the same subjects).\n",
    "2. **Normality**: Similar to the independent samples t-test, normality assumptions apply, but the t-test is often robust to violations for larger sample sizes due to the Central Limit Theorem.\n",
    "3. **The Differences are Normally Distributed**: The differences between paired observations should be approximately normally distributed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1632859b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>It's essential to assess these assumptions before conducting t-tests to ensure the validity of the results. Violations of these assumptions might lead to inaccurate conclusions or interpretations. There are also alternative tests available when assumptions are not met, such as non-parametric tests.</b>\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3936e3",
   "metadata": {},
   "source": [
    "> 2. Check normality of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cf3b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generating data for two groups with different variances\n",
    "np.random.seed(0)\n",
    "#np.random.normal(mean, scale~standard deviation (sd), size)\n",
    "group_a = np.random.normal(50, 10, 300)  # Group 1 normally distributed\n",
    "#np.random.exponential(scale~standard deviation (sd), size)\n",
    "group_b = np.random.exponential(50, 300) # Group 2 non normally distributed\n",
    "\n",
    "\n",
    "# Plotting distribution plot (histogram + kernel density estimation) on the second subplot\n",
    "sns.histplot(group_a, bins=30,kde=True, palette='bright',label='normal')\n",
    "sns.histplot(group_b, bins=30,kde=True, palette='bright', label='non normal')\n",
    "\n",
    "# Display legend\n",
    "plt.legend()\n",
    "\n",
    "# Set labels and title\n",
    "plt.xlabel('Values')\n",
    "plt.ylabel('Frequency')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a411e848",
   "metadata": {},
   "outputs": [],
   "source": [
    "normality_plot1, stat1 = stats.probplot(group_a, plot= plt, rvalue= True)\n",
    "normality_plot2, stat2 = stats.probplot(group_b, plot= plt,  rvalue= True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6d7e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing Shapiro-Wilk test\n",
    "statistic, p_value = stats.shapiro(group_a)\n",
    "\n",
    "# Printing test results\n",
    "print(f\"Shapiro-Wilk Test Statistic for group a: {statistic}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "\n",
    "alpha = 0.05  # Significance level\n",
    "\n",
    "if p_value > alpha:\n",
    "    print(\"Sample looks like it came from a normal distribution (fail to reject H0)\")\n",
    "else:\n",
    "    print(\"Sample does not look like it came from a normal distribution (reject H0)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38912cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing Shapiro-Wilk test\n",
    "statistic, p_value = stats.shapiro(group_b)\n",
    "\n",
    "# Printing test results\n",
    "print(f\"Shapiro-Wilk Test Statistic for group b: {statistic}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "\n",
    "alpha = 0.05  # Significance level\n",
    "\n",
    "if p_value > alpha:\n",
    "    print(\"Sample looks like it came from a normal distribution (fail to reject H0)\")\n",
    "else:\n",
    "    print(\"Sample does not look like it came from a normal distribution (reject H0)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e8d04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.shapiro(group_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01748f3b",
   "metadata": {},
   "source": [
    "> 3. check homogeneity of variance:\n",
    "Let's consider two groups, but the assumption of equal variances is violated. Group A has a small variance, whereas Group B has a much larger variance. This violates the assumption of homogeneity of variance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0b261d",
   "metadata": {},
   "source": [
    "In this example, `stats.levene()` from the `scipy` library performs **Levene's test** on the data from the two groups. The resulting test statistic and p-value help determine whether the assumption of equal variances between the groups holds. The significance level (often set at 0.05) determines whether the obtained p-value indicates significant differences in variances between the groups.\n",
    "\n",
    "- A higher value of the Levene test statistic generally indicates more substantial differences in variances between groups, suggesting a higher likelihood of rejecting the assumption of equal variances. Conversely, a smaller test statistic implies less variability between group variances, supporting the assumption of equal variances.\n",
    "\n",
    "- If the p-value is greater than the chosen significance level, it suggests that there is no significant difference in variances between the groups, indicating that the assumption of equal variances is met. Conversely, a p-value below the significance level suggests significant differences in variances between the groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143ea07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Generating data for two groups with different variances\n",
    "np.random.seed(0)\n",
    "group_1 = np.random.normal(50, 10, 30)  # Group 1 with SD 10\n",
    "group_2 = np.random.normal(50, 9, 30)  # Group 2 with SD 20\n",
    "\n",
    "# Performing Levene's test for equality of variances\n",
    "statistic, p_value = stats.levene(group_1, group_2)\n",
    "\n",
    "print(f\"Levene's test statistic: {statistic}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "\n",
    "alpha = 0.05  # Significance level\n",
    "\n",
    "if p_value > alpha:\n",
    "    print(\"The variances of the two groups are approximately equal.\")\n",
    "else:\n",
    "    print(\"The variances of the two groups are significantly different.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f38a4c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aec11ef",
   "metadata": {},
   "source": [
    "### Independent Samples t-test\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6a8096",
   "metadata": {},
   "source": [
    "This method conducts the independent sample t-test and returns only the t test statistic and it's associated p-value. For more information about this method, please refer to the official [documentation page](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_ind.html).\n",
    "\n",
    "\n",
    "- Calculate the T-test for the means of **two independent samples** of scores.\n",
    "- This is a test for the null hypothesis that 2 independent samples have identical average (expected) values. \n",
    "\n",
    "        - H0: populations have identical variances by default.\n",
    "        - H1: populations have different variances.\n",
    "- This test assumes that \n",
    "1. samples are independent,  \n",
    "2. normally distributed, \n",
    "3. variances are homogenous.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebcfbc3f",
   "metadata": {},
   "source": [
    "> Dummy example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a8decb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Independent Samples t-test example\n",
    "np.random.seed(0)\n",
    "group_A_scores = np.random.normal(75, 10, 30)  # Generating scores for Group A\n",
    "group_B_scores = np.random.normal(70, 12, 30)  # Generating scores for Group B\n",
    "\n",
    "t_statistic, p_value = stats.ttest_ind(group_A_scores, group_B_scores)\n",
    "print(\"Independent Samples t-test:\")\n",
    "print(f\"T-statistic: {t_statistic}\")\n",
    "print(f\"P-value: {p_value}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1d34e9",
   "metadata": {},
   "source": [
    "> Simulated dataset from a book"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211061a3",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "Question: Is there mean difference between male and female blood pressure after treatment?\n",
    "</div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc83ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#df = pd.read_csv(\"https://raw.githubusercontent.com/researchpy/Data-sets/master/blood_pressure.csv\")\n",
    "df = pd.read_csv(\"../data/blood_pressure.csv\")\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0349fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "male = df['bp_after'][df['sex'] == 'Male']\n",
    "female = df['bp_after'][df['sex'] == 'Female']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a9e686",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_both = {\n",
    "    'male':male,\n",
    "    'female':female\n",
    "}\n",
    "type(df_both)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342d7ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(df_both)\n",
    "plt.title('Boxplot of blood pressure after treatment based on gender')\n",
    "plt.xlabel('gender')\n",
    "plt.ylabel('blood pressure')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6bbfee",
   "metadata": {},
   "source": [
    "#### check assumptions:\n",
    "\n",
    " 1. both are independent dataset\n",
    " 2. normality\n",
    " 3. variance homogeneity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540c88b0",
   "metadata": {},
   "source": [
    "> normality test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128aaa03",
   "metadata": {},
   "outputs": [],
   "source": [
    "normality_plot1, stat1 = stats.probplot(male, plot= plt, rvalue= True)\n",
    "normality_plot2, stat2 = stats.probplot(female, plot= plt,  rvalue= True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c691fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(normality_plot2[0],normality_plot2[1], marker='o', linestyle='-')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60f85d9",
   "metadata": {},
   "source": [
    "> more on normality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6cc94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing Shapiro-Wilk test\n",
    "statistic, p_value = stats.shapiro(female)\n",
    "\n",
    "# Printing test results\n",
    "print(f\"Shapiro-Wilk Test Statistic for group b: {statistic}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "\n",
    "alpha = 0.05  # Significance level\n",
    "\n",
    "if p_value > alpha:\n",
    "    print(\"Sample looks like it came from a normal distribution (fail to reject H0)\")\n",
    "else:\n",
    "    print(\"Sample does not look like it came from a normal distribution (reject H0)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49184ad5",
   "metadata": {},
   "source": [
    "> check on variance homogeneity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1832585b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Performing Levene's test for equality of variances\n",
    "statistic, p_value = stats.levene(male, female)\n",
    "\n",
    "print(f\"Levene's test statistic: {statistic}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "\n",
    "alpha = 0.05  # Significance level\n",
    "\n",
    "if p_value > alpha:\n",
    "    print(\"The variances of the two groups are approximately equal.\")\n",
    "else:\n",
    "    print(\"The variances of the two groups are significantly different.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb21ac62",
   "metadata": {},
   "source": [
    "> Finally carry out independent t test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c332f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "statistic, p_value = stats.ttest_ind(df['bp_after'][df['sex'] == 'Male'],\n",
    "                df['bp_after'][df['sex'] == 'Female'])\n",
    "\n",
    "\n",
    "print(f\"t's test statistic: {statistic}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "\n",
    "if p_value > alpha:\n",
    "    print(\"The means of the two groups are approximately equal.\")\n",
    "else:\n",
    "    print(\"The means of the two groups are significantly different.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373dd5cf",
   "metadata": {},
   "source": [
    "- This is a test for the null hypothesis that 2 independent samples have identical average (expected) values. \n",
    "\n",
    "        - H0: populations have identical variances by default.\n",
    "        - H1: populations have different variances.\n",
    "        \n",
    ">Interpretation:\n",
    "1. p= 0.001 (which is <0.05), so we can reject the null hypothesis (H0) and accept the alternative hypothesis(H1).\n",
    "2. The average blood pressure after the treatment for males, mean= 155.2, was significantly higher than females, mean= 147.2 (144.2, 150.2); t(118)= 3.3480, p= 0.001.\n",
    "\n",
    "**There is a statistically significant difference in the average post blood pressure between males and females.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe71ad0",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "Question: Is there mean difference between male and female blood pressure **before** treatment?\n",
    "</div> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce51cd75",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7b7029",
   "metadata": {},
   "source": [
    "###  Paired Samples t-test <br>\n",
    "\n",
    "Specifically, the paired t-test assesses whether the mean difference between paired observations is equal to a specified value.\n",
    "\n",
    "For a paired t-test, the hypotheses are typically formulated as follows:\n",
    "\n",
    "    - Null Hypothesis (H0): The mean difference between paired observations is equal to zero (or another specified value).\n",
    "\n",
    "    - Alternative Hypothesis (H1): The mean difference between paired observations is not equal to zero (or differs from the specified value). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1337c254",
   "metadata": {},
   "source": [
    "#### check assumptions:\n",
    "\n",
    " 1. Both are dependent dataset\n",
    " 2. Normality\n",
    " 3. The Differences are Normally Distributed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f15654",
   "metadata": {},
   "source": [
    "> dummy dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deecca79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "np.random.seed(1)\n",
    "before_treatment = np.random.normal(120, 10, 50)\n",
    "after_treatment = before_treatment + np.random.uniform(-20, 20, 50)  # adding values to make it different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323a7cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot([before_treatment, after_treatment])\n",
    "#sns.boxplot(female)\n",
    "plt.title('before and after treatment')\n",
    "plt.xlabel('treatment')\n",
    "plt.ylabel('score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a893a9d7",
   "metadata": {},
   "source": [
    "> 2. normality test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c05f2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "normality_plot1, stat1 = stats.probplot(before_treatment, plot= plt, rvalue= True)\n",
    "normality_plot2, stat2 = stats.probplot(after_treatment, plot = plt,  rvalue= True )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3b4119",
   "metadata": {},
   "source": [
    "> 3. the difference normality test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8c4097",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_difference = after_treatment - before_treatment\n",
    "sns.histplot(sampling_difference, bins=30,kde=True, palette='bright',label='normal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4320af72",
   "metadata": {},
   "outputs": [],
   "source": [
    "normality_plot1, stat1 = stats.probplot(sampling_difference, plot= plt, rvalue= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8e8821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing Shapiro-Wilk test\n",
    "statistic, p_value = stats.shapiro(sampling_difference)\n",
    "\n",
    "# Printing test results\n",
    "print(f\"Shapiro-Wilk Test Statistic for sampling difference: {statistic}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "\n",
    "alpha = 0.05  # Significance level\n",
    "\n",
    "if p_value > alpha:\n",
    "    print(\"Sample looks like it came from a normal distribution (fail to reject H0)\")\n",
    "else:\n",
    "    print(\"Sample does not look like it came from a normal distribution (reject H0)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd0e1f8",
   "metadata": {},
   "source": [
    "**In this case, the assumption of normality in differences between paired observations is violated. The differences between paired observations don't follow a normal distribution.** \n",
    "> If we carry out paired t test, it might not be accurate or reliable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278716e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_statistic, p_value = stats.ttest_rel(before_treatment, after_treatment)\n",
    "print(\"Paired Samples t-test with Violation:\")\n",
    "print(f\"T-statistic: {t_statistic}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "\n",
    "\n",
    "if p_value > alpha:\n",
    "    print(\"The mean difference between paired observations is equal to zero (fail to reject H0)\")\n",
    "else:\n",
    "    print(\"The mean difference between paired observations is not equal to zero (reject H0)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fefa06",
   "metadata": {},
   "source": [
    "**Wilcoxon Signed-Rank Test**: \n",
    "- The Wilcoxon signed-rank test is a non-parametric alternative to the paired samples t-test. \n",
    "- It doesn't assume normality or homogeneity of variances and tests whether the median of the differences between paired observations differs significantly from zero.\n",
    "\n",
    "        - Null Hypothesis (H0): The null hypothesis for the Wilcoxon Signed-Rank Test states that there is no difference between the medians of the paired observations (i.e., the median of the differences between pairs equals zero).\n",
    "        - Alternative Hypothesis (H1): The alternative hypothesis complements the null hypothesis and typically suggests that there is a difference between the medians of the paired observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cdad2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing Wilcoxon Signed-Rank Test\n",
    "statistic, p_value = stats.wilcoxon(before_treatment, after_treatment)\n",
    "\n",
    "# Printing test results\n",
    "print(f\"Wilcoxon Signed-Rank Test Statistic: {statistic}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "\n",
    "alpha = 0.05  # Significance level\n",
    "\n",
    "if p_value < alpha:\n",
    "    print(\"Reject the null hypothesis: There is a significant difference.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: No significant difference.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd74d35",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "Question: Is there mean difference between male and female blood pressure BEFORE AND AFTER treatment?\n",
    "</div> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fc6a86",
   "metadata": {},
   "source": [
    "# Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d469892",
   "metadata": {},
   "source": [
    "Correlation is a statistical measure that describes the strength and direction of a relationship between two numerical variables. It helps in understanding how changes in one variable are associated with changes in another variable.\n",
    "\n",
    "- Types of Correlation:\n",
    "\n",
    "1. Pearson Correlation Coefficient (Pearson's r):\n",
    "    - Measures linear correlation between two continuous variables. Ranges from -1 to +1.\n",
    "    - +1 indicates a perfect positive linear relationship.\n",
    "    - -1 indicates a perfect negative linear relationship.\n",
    "    - 0 indicates no linear relationship.\n",
    "    - Assumes a linear relationship and normality of data.\n",
    "2. Spearman's Rank Correlation (Spearman's rho):\n",
    "    - Measures monotonic relationship between two variables. *Monotonic Relationships*: whether the relationship between variables can be described by a monotonic function. Monotonicity means that as one variable increases, the other variable either consistently increases or decreases (but not necessarily at a constant rate).\n",
    "    - Based on the ranks of the data (ordinal relationship).\n",
    "    - Also ranges from -1 to +1.\n",
    "    - Robust to outliers and non-linear relationships.\n",
    "    - Spearman's correlation does not assume a linear relationship between variables. It only assumes that the variables are related by a monotonic function.\n",
    "\n",
    "3. Kendall's Tau:\n",
    "    - Measures ordinal association between two variables.\n",
    "    - Similar to Spearman's correlation but focuses on concordant and discordant pairs of ranks.\n",
    "\n",
    "\n",
    "- Visualizing correlations can provide a clear understanding of the relationships between variables in a dataset. Heatmaps are commonly used to visualize correlation matrices, especially when dealing with multiple variables.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b496e0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.corr?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37c1ce7",
   "metadata": {},
   "source": [
    "### Toy example\n",
    "\n",
    "> Pearson's and Spearman's correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff7256e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample dataset with numerical columns 'X' and 'Y'\n",
    "data = {'X': [1, 2, 3, 4, 5], 'Y': [2, 4, 6, 8, 10], 'Z': [1,10,19,2,3]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Calculate Pearson correlation coefficient\n",
    "pearson_corr_x_y = df['X'].corr(df['Y'])  # Pandas corr() function\n",
    "print(f\"Pearson's correlation coefficient between x and y: {pearson_corr_x_y:.2f}\")\n",
    "\n",
    "pearson_corr_x_z = df['X'].corr(df['Z'])  \n",
    "print(f\"Pearson's correlation coefficient between x and z: {pearson_corr_x_z:.2f}\")\n",
    "\n",
    "\n",
    "corr_matrix = df.corr()\n",
    "print(corr_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34a003f",
   "metadata": {},
   "source": [
    "This code snippet demonstrates using Pandas' corr() function to calculate the Pearson correlation coefficient between two columns ('X' and 'Y') in a DataFrame.\n",
    "\n",
    "For Spearman and Kendall correlations, you can use `df.corr(method='spearman')` or `df.corr(method='kendall')` respectively, specifying the method parameter in the corr() function.\n",
    "\n",
    "Understanding correlations is essential for identifying relationships between variables in your data, helping in feature selection, and guiding further analysis or modeling decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4558b6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df is your DataFrame with columns X and Y\n",
    "spearman_corr_x_z = df[['X', 'Y']].corr(method='spearman')  # Computing Spearman's rank correlation coefficient\n",
    "print(f\"Spearman's correlation coefficient between x and zy: {pearson_corr_x_z:.5f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5468b815",
   "metadata": {},
   "source": [
    "> Kendall's"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab754e1",
   "metadata": {},
   "source": [
    "- We create a simple DataFrame where 'X' represents the rankings of individuals in Exam X and 'Y' represents the rankings of the same individuals in Exam Y.\n",
    "- The rankings are intentionally placed in a way that doesn't follow a perfect linear relationship but exhibits an ordinal association.\n",
    "- Then, we compute Kendall's correlation coefficient using Pandas' corr() method with the method='kendall' parameter, which calculates Kendall's τ for the given DataFrame columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22606967",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Creating an example DataFrame with rankings of two exams (X and Y)\n",
    "data = {\n",
    "    'X': [1, 2, 3, 4, 5],  # Rankings for Exam X\n",
    "    'Y': [3, 1, 4, 2, 5]   # Rankings for Exam Y\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n",
    "\n",
    "# Compute Kendall's correlation coefficient\n",
    "kendall_corr = df[['X', 'Y']].corr(method='kendall')\n",
    "print(\"\\nKendall's correlation coefficient:\")\n",
    "print(kendall_corr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8046d846",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Let's visualize the correlation between features:</b> Use heatmap!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943dd1b4",
   "metadata": {},
   "source": [
    ">In Pandas, the` corr()` method calculates the correlation matrix by default using the Pearson correlation coefficient. \n",
    "\n",
    "> the correlation matrix and the subsequent heatmap visualization consider only numeric variables, which can be used to explore relationships among continuous measurements in the Iris dataset or any other dataset with mixed data types. Adjust this code as needed for your specific dataset and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507b3e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Loading the Iris dataset from Seaborn\n",
    "#iris = sns.load_dataset('iris')\n",
    "\n",
    "iris = pd.read_csv(\"../data/iris.csv\")\n",
    "\n",
    "# Selecting only numeric columns for correlation calculation\n",
    "feature_columns = iris.drop(['species', 'species_id'], axis=1)\n",
    "\n",
    "# Calculating the correlation matrix\n",
    "corr_matrix = feature_columns.corr()\n",
    "print(corr_matrix)\n",
    "\n",
    "# Plotting a heatmap of the correlation matrix\n",
    "plt.figure(figsize=(4, 4))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f', annot_kws={\"size\": 10})\n",
    "plt.title('Correlation Heatmap of Iris Dataset ')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc32fcc3",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "Question: Use various types of correlations for the iris dataset. Identify which features are similar and dissimilar?\n",
    "</div> "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
