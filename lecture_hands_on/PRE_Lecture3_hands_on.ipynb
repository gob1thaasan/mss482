{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6027a45f-d731-4ff1-8527-b4db811bb2f9",
   "metadata": {
    "id": "fRuRcAt3F_wS"
   },
   "source": [
    "\n",
    "# MSS482 - GRAPHING TECHNOLOGY IN MATHEMATICS AND SCIENCE\n",
    "\n",
    "**SEMESTER 1 2023/2024**\n",
    "\n",
    "\n",
    ">R.U.Gobithaasan (2023). School of Mathematical Sciences, Universiti Sains Malaysia.\n",
    "[Official Website](https://math.usm.my/academic-profile/705-gobithaasan-rudrusamy) \n",
    "\n",
    "\n",
    "<p align=\"center\">\n",
    "     © 2023 R.U. Gobithaasan All Rights Reserved.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9069ae-3da6-41b9-88f1-cb26da15581c",
   "metadata": {},
   "source": [
    "# Analysing more than one variable\n",
    "- https://www.pythonfordatascience.org/independent-samples-t-test-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db82e975-28ad-49ac-9960-82538ce11fd0",
   "metadata": {},
   "source": [
    "3.1 Anlyzing dataset with <br>\n",
    "    a) Continuous features <br>\n",
    "    b) Categorical features <br>\n",
    "\n",
    "3.2. t-Test <br>\n",
    "    a) Independent Samples t-test <br>\n",
    "    b) Paired Samples t-test <br>\n",
    "\n",
    "\n",
    "3.3 Correlation\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14ade7d",
   "metadata": {},
   "source": [
    "### requirements\n",
    "\n",
    "> Install the following: `!python -m pip install pandas`\n",
    "1. pandas\n",
    "2. researchpy\n",
    "3. statsmodels\n",
    "4. matplotlib\n",
    "5. seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31aad3b9-a5ff-430c-bda0-922d8e3de635",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Dataset: Online Dataset sources\n",
    "\n",
    "**Online Sources:** \n",
    "- Google Dataset Search: https://datasetsearch.research.google.com/ \n",
    "- Kaggle: https://www.kaggle.com/datasets \n",
    "- UCI Machine Learning Repository: https://archive.ics.uci.edu/ml/datasets.php \n",
    "- Earth Data: https://www.earthdata.nasa.gov/\n",
    "- Scikit Dataset: https://scikit-learn.org/stable/datasets.html\n",
    "- https://github.com/gob1thaasan/Data-sets \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0cf54e",
   "metadata": {},
   "source": [
    "### Tips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba723a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Magic command to display Matplotlib plots inline :https://ipython.readthedocs.io/en/stable/interactive/magics.html\n",
    "%matplotlib inline\n",
    "# To ignore warnings, use the following code to make the display more attractive.\n",
    "# Import seaborn and matplotlib.\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa413f35",
   "metadata": {},
   "source": [
    "# Analyzing Continuous & Categorical Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d8fb3a",
   "metadata": {},
   "source": [
    "## Numeric Data\n",
    "> Numeric data is information that can be expressed as a number: Can be continuous or discrete.\n",
    "\n",
    "Continuous data is data that can take any value. Height, weight, temperature and length are all examples of continuous data. Some continuous data will change over time; the weight of a baby in its first year or the temperature in a room throughout the day. This data is best shown on a line graph as this type of graph can show how the data changes over a given period of time. Other continuous data, such as the heights of a group of children on one particular day, is often grouped into categories to make it easier to interpret.\n",
    "\n",
    "Discrete data is information that can only take certain values. These values don’t have to be whole numbers. For example, the number of hospital visit to schedule for the week and the number of students attending a lecture each day. This type of data is often represented using tally charts, bar charts or pie charts.\n",
    "\n",
    "\n",
    "---\n",
    "## Categorical Data\n",
    "- https://www.datacamp.com/tutorial/categorical-data\n",
    "\n",
    "Data that can be categorized but lacks an inherent hierarchy or order is known as categorical data. In other words, there is no mathematical connection between the categories. A person's gender (male/female), eye color (blue, green, brown, etc.), type of vehicle they drive (sedan, SUV, truck, etc.), or the kind of fruit they consume (apple, banana, orange, etc.) are examples of categorical data.\n",
    "\n",
    "- In simple terms, categorical data is information that can be put into categories.\n",
    "- Since the majority of machine learning algorithms are created to operate with numerical data, categorical data is handled differently from numerical data in this field. \n",
    "- Before categorical data can be utilized as input to a machine learning model, it must first be transformed into numerical data. \n",
    "- This process of converting categorical data into numeric representation is known as encoding.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e26ba98",
   "metadata": {},
   "source": [
    "### Univariate: Weight of a group (toy example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbfe909",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "x = np.array([148, 154, 158, 160, 161, 162, 166, 170, 182, 195, 236])\n",
    "\n",
    "# Plotting distribution plot (histogram + kernel density estimation) on the second subplot\n",
    "sns.histplot(x, kde=True, color='salmon')\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a98c584",
   "metadata": {},
   "source": [
    "- Kernel Density Estimation (KDE) is a non-parametric method used for estimating the probability density function (PDF) of a continuous random variable. It's a technique to visualize the distribution of data in a smoothed continuous form.\n",
    "- In simple terms, KDE provides a smooth curve that approximates the shape of the underlying probability distribution of a dataset. It estimates the density function by placing a kernel (a smooth, symmetric function such as a Gaussian or Epanechnikov kernel) at each data point and summing up these kernels to create a smooth curve that represents the overall distribution of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997b3492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Seaborn to create the boxplot\n",
    "sns.boxplot(data=x)  # You can specify your own color palette\n",
    "\n",
    "# Setting labels and title\n",
    "plt.xlabel('Categories')\n",
    "plt.ylabel('Values')\n",
    "plt.title('Boxplot Example for toy data')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc8e96e",
   "metadata": {},
   "source": [
    "#### Multivariate: Fictional blood-pressure data\n",
    "\n",
    "Multivariate analysis refers to the analysis of datasets involving more than one variable. It aims to understand the relationships between multiple variables simultaneously and uncover patterns, dependencies, and interactions among them.\n",
    "\n",
    "- There are various techniques and methods for multivariate analysis, each serving different purposes based on the nature of the data and the objective of the analysis. \n",
    "\n",
    "- When performing multivariate analysis, it's crucial to understand the assumptions of each technique and interpret the results accordingly. Additionally, visualization techniques like scatter plots, heatmap, and pair plots can aid in understanding relationships between multiple variables.\n",
    "\n",
    "- The choice of technique depends on the research question, the nature of the data, and the specific objectives of the analysis. Depending on your dataset and research objectives, you can select an appropriate multivariate analysis technique to derive insights and patterns from your data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff8118c",
   "metadata": {},
   "source": [
    "\n",
    "### Example: blood pressure of patients before and after treatment (taken from a book Stata 11 manual: https://www.stata-press.com/data/r11/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fc2c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/researchpy/Data-sets/master/blood_pressure.csv\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e89a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2c4cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06b94f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534e626d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Types of feature?</b>  Classify the features into continuous and categorical dataset\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3df8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sex'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50dec10",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_group = df['agegrp'].unique()\n",
    "print(age_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156d2c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['bp_before'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c4915d",
   "metadata": {},
   "source": [
    "- Blood pressure is an example of continuous data. Blood pressure can be measured to as many decimals as the measuring instrument allows. For example, although a typical blood pressure cuff does not provide decimal places, a digital blood pressure monitor (often used in hospital settings) may have the capacity to determine the blood pressure to 3 decimal places, and even more powerful blood pressure monitors may be developed that can read a patients blood pressure to 5 decimal places."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad36032",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Sampling:</b> Randomly choosing some samples from a population.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62acecef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9ad2f6",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis: Visualizatiton\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8da5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the plot style (e.g., 'ggplot', 'seaborn-dark', 'fivethirtyeight', etc.)\n",
    "'''\n",
    "'seaborn' - Seaborn-like style\n",
    "'ggplot' - Style similar to ggplot in R\n",
    "'fivethirtyeight' - Style similar to plots on FiveThirtyEight\n",
    "'classic' - Classic Matplotlib style\n",
    "'bmh' - Style from the Bayesian Methods for Hackers book\n",
    "'dark_background' - Dark background style\n",
    "'tableau-colorblind10' - Tableau colorblind 10 palette\n",
    "'Solarize_Light2' - Light background with strong colors\n",
    "'seaborn-dark-palette' - Seaborn dark palette\n",
    "'seaborn-whitegrid' - Seaborn style with white grid lines\n",
    "'''\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "df_gender = df.groupby('sex')\n",
    "df_gender.boxplot()\n",
    "df_gender.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0938a1",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Exercise:</b> Try plotting boxplot grouped by age group.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5290305d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6054da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# customizing dataframe for further analysis.\n",
    "df_male_after = df['bp_after'][df['sex'] == 'Male']\n",
    "df_female_after = df['bp_after'][df['sex'] == 'Female']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd0ba48",
   "metadata": {},
   "outputs": [],
   "source": [
    "after_treatment_gender_data = {'male': np.array(df_male_after), \n",
    "                          'female': np.array(df_female_after)}\n",
    "df_after_treatment_gender =pd.DataFrame(after_treatment_gender_data)\n",
    "df_after_treatment_gender.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664dbf26",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=df_after_treatment_gender)\n",
    "\n",
    "plt.title('Boxplot of blood pressure after treatment based on gender')\n",
    "plt.xlabel('gender')\n",
    "plt.ylabel('blood pressure')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48756d56",
   "metadata": {},
   "source": [
    "Seaborn offers a variety of color palettes that you can use for your plots. Here is a list of some of the named palettes available in Seaborn:\n",
    "\n",
    "- Sequential Color Palettes:\n",
    "'rocket'\n",
    "'mako'\n",
    "'flare'\n",
    "'crest'\n",
    "'cividis'\n",
    "'viridis'\n",
    "'plasma'\n",
    "'inferno'\n",
    "'magma'\n",
    "\n",
    "- Diverging Color Palettes:\n",
    "'coolwarm'\n",
    "'RdBu'\n",
    "'PuOr'\n",
    "'BrBG'\n",
    "'PiYG'\n",
    "'PRGn'\n",
    "\n",
    "- Qualitative Color Palettes:\n",
    "'pastel'\n",
    "'bright'\n",
    "'dark'\n",
    "'deep'\n",
    "'colorblind'\n",
    "'Set1', 'Set2', 'Set3'\n",
    "'tab10', 'tab20', 'tab20b', 'tab20c'\n",
    "\n",
    "- Other Palettes:\n",
    "'husl'\n",
    "'hls'\n",
    "'twilight'\n",
    "'twilight_shifted'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b57cb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting distribution plot (histogram + kernel density estimation) on the second subplot\n",
    "sns.histplot(df_male_after, kde=True, palette='mako')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94027474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting distribution plot (histogram + kernel density estimation) on the second subplot\n",
    "sns.histplot(df_female_after, kde=True, palette='bright')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5eb6c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting distribution plot (histogram + kernel density estimation) on the second subplot\n",
    "sns.histplot(df_after_treatment_gender, kde=True, palette='bright')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16245b9",
   "metadata": {},
   "source": [
    " <div class=\"alert alert-block alert-danger\">\n",
    "<b>What type of distribution does this feature possess?</b> Try plotting probability plot.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c752f6",
   "metadata": {},
   "source": [
    "A probability plot, also known as a Q-Q (quantile-quantile) plot, is a graphical method used to assess whether a dataset follows a particular theoretical distribution, such as the normal distribution.\n",
    "\n",
    "The main purpose of a probability plot is to visually compare the quantiles of a dataset against the quantiles of a theoretical distribution. If the data follows the theoretical distribution closely, the points on the plot will fall approximately along a straight line, indicating that the data fits that distribution well.\n",
    "\n",
    "For instance, when assessing normality using a Q-Q plot:\n",
    "\n",
    "- If the data points form a straight line, it indicates the data is normally distributed.\n",
    "- If the points deviate from a straight line, it suggests a departure from normality.\n",
    "\n",
    ">`probplot` optionally calculates a best-fit line for the data and plots the\n",
    "results using Matplotlib or a given plot function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07419873",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Using a custom color palette\n",
    "custom_palette = sns.color_palette(['#FF5733', '#33FF57', '#3357FF'])  # List of RGB/hex colors: https://www.color-hex.com/\n",
    "sns.set_palette(custom_palette)\n",
    "\n",
    "sampling_male= np.array(df['bp_after'][df['sex'] == 'Male'])\n",
    "\n",
    "normality_plot, stat = stats.probplot(sampling_male, plot= plt, rvalue= True,)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6583c0eb",
   "metadata": {},
   "source": [
    " <div class=\"alert alert-block alert-danger\">\n",
    "<b>What type of distribution does female samples possess?</b> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1a3368",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "194656d0",
   "metadata": {},
   "source": [
    " <div class=\"alert alert-block alert-danger\">\n",
    "<b>What type of distribution does the sampling difference between male and female possess?</b> Plot the probability plot and its distribution.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cbf94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Using a custom color palette\n",
    "custom_palette = sns.color_palette(['#FF5733', '#33FF57', '#3357FF'])  # List of RGB/hex colors: https://www.color-hex.com/\n",
    "sns.set_palette(custom_palette)\n",
    "\n",
    "sampling_difference = np.array(df['bp_after'][df['sex'] == 'Male'])- np.array(df['bp_after'][df['sex'] == 'Female'])\n",
    "\n",
    "normality_plot, stat = stats.probplot(sampling_difference, plot= plt, rvalue= True,)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a24af4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting distribution plot (histogram + kernel density estimation) on the second subplot\n",
    "sns.histplot(sampling_difference, kde=True, palette=custom_palette)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135303bb",
   "metadata": {},
   "source": [
    "> This shows our data is normalized, although, at two ends the data does not exactly fit the red line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1708a92f",
   "metadata": {},
   "source": [
    "Another method to check for the normality is to use the Shapiro-Wilk test.\n",
    "- The value of this statistic tends to be high (close to 1) for samples drawn from a normal distribution.\n",
    "- The null hypothesis of the Shapiro-Wilk test is that the data are normally distributed. \n",
    "- If the p-value resulting from the test is less than a chosen significance level (commonly 0.05), we reject the null hypothesis, concluding that the data do not follow a normal distribution.\n",
    "- If the p-value is “small” - that is, if there is a low probability of sampling data from a normally distributed population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2ee268",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.shapiro(sampling_difference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd24a211",
   "metadata": {},
   "source": [
    "Both the statistic and p-value are high, 98%  and 71% respectively, which means our residual data is normally distributed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee273695",
   "metadata": {},
   "source": [
    "---\n",
    "## More on Categorical Dataset\n",
    "- https://www.datacamp.com/tutorial/categorical-data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c40729",
   "metadata": {},
   "source": [
    " - This classic dataset contains the prices and other attributes of almost 54,000 diamonds. It's a great dataset for beginners learning to work with data analysis and visualization.\n",
    " https://www.kaggle.com/datasets/shivam2503/diamonds\n",
    "\n",
    " Below is a sample of the dataset and its the features:\n",
    "\n",
    "- price: price in US dollars (find the range)\n",
    "\n",
    "- carat: weight of the diamond (find the range)\n",
    "\n",
    "- cut: quality of the cut (find the categories)\n",
    "\n",
    "- color: diamond colour, from J (worst) to D (best)\n",
    "\n",
    "- clarity: a measurement of how clear the diamond is (I1 (worst), SI2, SI1, VS2, VS1, VVS2, VVS1, IF (best))\n",
    "\n",
    "- Symmetry (find the categories)\n",
    "\n",
    "- Report (find the categories)\n",
    "\n",
    "- Polish (find the categories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbf8f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv using pandas\n",
    "data = pd.read_csv('https://raw.githubusercontent.com/pycaret/pycaret/master/datasets/diamond.csv')\n",
    "\n",
    "# check the data types\n",
    "data.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59230169",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Types of feature?</b>  Classify the features into continuous and categorical dataset\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ef022d",
   "metadata": {},
   "source": [
    "- Well, all the columns in this example are categorical except for `Carat Weight` and `Price.` Let’s see if we are right about this by checking the default data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25e4c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# check the head of dataframe\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc413285",
   "metadata": {},
   "source": [
    "`value_counts()` is a function in the pandas library that returns the frequency of each unique value in a categorical data column. This function is useful when you want to get a quick understanding of the distribution of a categorical variable, such as the most common categories and their frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566c3c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv using pandas\n",
    "import pandas as pd\n",
    "data = pd.read_csv('https://raw.githubusercontent.com/pycaret/pycaret/master/datasets/diamond.csv')\n",
    "\n",
    "# check value counts of Cut column\n",
    "bar_data = data['Cut'].value_counts()\n",
    "bar_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb92418",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cut_counts = data['Cut'].value_counts()\n",
    "df_type_cut = pd.DataFrame({'cut type': list(cut_counts.index), 'count': list(cut_counts.values)})\n",
    "df_type_cut.plot.bar(x='cut type', y='count')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4387144",
   "metadata": {},
   "source": [
    "`groupby()` is a function in Pandas that allows you to group data by one or more columns and apply aggregate functions such as sum, mean, and count. This function is useful when you want to perform more complex analysis on categorical data, such as computing the average of a numeric variable for each category. Let’s see an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f9850f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying groupby() function to\n",
    "d_color = data.groupby('Color')\n",
    "# Let's print the first entries in all the groups formed.\n",
    "\n",
    "d_color.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2ef1f2",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Find the details of a particular group:</b>`get_group()`\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b363f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_color.get_group('D')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d0ee5d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bdfbb471",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Let's convert a categorical feature into numerical representation</b>: We can then carry out more computation & calculation for modelling and machine learning tasks.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef0bf27",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Cut']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef607c45",
   "metadata": {},
   "source": [
    "One- hot encoding is a process of representing categorical data as a set of binary values, where each category is mapped to a unique binary value. \n",
    "- In this representation, only one bit is set to 1, and the rest are set to 0, hence the name \"one hot.\" \n",
    "- This is commonly used in machine learning to convert categorical data into a format that algorithms can process.\n",
    "- The `pd.get_dummies() function in pandas performs one-hot encoding by converting the categorical variable ('Cut') into multiple binary columns representing each category. The new columns have binary values (0 or 1) indicating the presence of each category in the original data.\n",
    "- For example, we can perform one-hot encoding on categorical features using SKLearn, then train a basic machine learning model (Logistic Regression) using the encoded features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7dab3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply get_dummies function\n",
    "df_encoded = pd.get_dummies(data[\"Cut\"])\n",
    "df_encoded .tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a40d181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting one-hot encoded DataFrame to 0-1 array\n",
    "array_representation = df_encoded.values\n",
    "print(array_representation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a9c161",
   "metadata": {},
   "source": [
    "We will learn more on Analysis of Categorical Data in the last week of this course\n",
    "- https://ethanweed.github.io/pythonbook/05.01-chisquare.html \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1649a9a0",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Carry out similar tasks for iris dataset. Continue the code below.</b>\n",
    "</div>\n",
    "\n",
    "- Boxplot\n",
    "- Scatterplot\n",
    "- Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca32297",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#df = pd.read_csv(\"https://raw.githubusercontent.com/researchpy/Data-sets/master/blood_pressure.csv\")\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/Opensourcefordatascience/Data-sets/master/Iris_Data.csv\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a21bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb6429b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a11c6cc",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>The rest of sections  will be updated by 29/12/2023...</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f3351d",
   "metadata": {},
   "source": [
    "# t-Tests\n",
    "- https://www.pythonfordatascience.org/parametric-assumptions-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e02e4cf",
   "metadata": {},
   "source": [
    "#### ASSUMPTION CHECK\n",
    "The assumptions in this section need to be met in order for the test results to be considered valid. A more in-depth look at parametric assumptions is provided here, which includes some potential remedies.\n",
    "\n",
    "> THE TWO SAMPLES ARE INDEPENDENT:\n",
    "This assumption is tested when the study is designed. What this means is that no individual has data in group A and B; mutually exclusive.\n",
    "\n",
    "> POPULATION DISTRIBUTIONS ARE NORMAL:\n",
    "One of the assumptions is that the sampling distribution is normally distributed. This test of normality applies to the difference in values between the groups. \n",
    "\n",
    "        - We can use probability plot available in Scipy.stat\n",
    "        - We can also use Shapiro-Wilk test. This can be completed using the shapiro() method from Scipy.stats.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1632859b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6387dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "x = np.array([148, 154, 158, 160, 161, 162, 166, 170, 182, 195, 236])\n",
    "\n",
    "# Example of using a Seaborn default color palette; {deep, muted, bright, pastel, dark, colorblind}\n",
    "sns.set_palette('deep')\n",
    "# Plotting distribution plot (histogram + kernel density estimation) on the second subplot\n",
    "sns.histplot(x, kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7320a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "normality_plot, stat = stats.probplot(x, plot= plt, rvalue= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6167e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "stats.shapiro(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d213f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "sns.set_palette('bright')\n",
    "# Generate some random data\n",
    "data = np.random.normal(size=1000)\n",
    "# Plotting distribution plot (histogram + kernel density estimation) on the second subplot\n",
    "sns.histplot(data, kde=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64af6386",
   "metadata": {},
   "outputs": [],
   "source": [
    "normality_plot, stat = stats.probplot(data, plot= plt, rvalue= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6dc8b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "stats.shapiro(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7480b282",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Generate some random data\n",
    "data = np.random.exponential(3.45, 10000)\n",
    "\n",
    "# Plotting distribution plot (histogram + kernel density estimation) on the second subplot\n",
    "sns.histplot(data, kde=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7625df89",
   "metadata": {},
   "outputs": [],
   "source": [
    "normality_plot, stat = stats.probplot(data, plot= plt, rvalue= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0e7864",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "stats.shapiro(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f38a4c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aec11ef",
   "metadata": {},
   "source": [
    "### Independent Samples t-test\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6a8096",
   "metadata": {},
   "source": [
    "This method conducts the independent sample t-test and returns only the t test statistic and it's associated p-value. For more information about this method, please refer to the official [documentation page](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_ind.html).\n",
    "\n",
    "\n",
    "- Calculate the T-test for the means of two independent samples of scores.\n",
    "- This is a test for the null hypothesis that 2 independent samples have identical average (expected) values. \n",
    "- This test assumes that the populations have identical variances by default.\n",
    "\n",
    "        - H0: populations have identical variances by default.\n",
    "        - H1: populations have different variances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc83ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/researchpy/Data-sets/master/blood_pressure.csv\")\n",
    "\n",
    "\n",
    "import scipy.stats as stats\n",
    "stats.ttest_ind(df['bp_after'][df['sex'] == 'Male'],\n",
    "                df['bp_after'][df['sex'] == 'Female'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373dd5cf",
   "metadata": {},
   "source": [
    ">Interpretation:\n",
    "1. p= 0.001 (which is <0.05), so we can reject the null hypothesis (H0) and accept the alternative hypothesis(H1).\n",
    "2. The average blood pressure after the treatment for males, mean= 155.2, was statistically signigicantly higher than females, mean= 147.2 (144.2, 150.2); t(118)= 3.3480, p= 0.001.\n",
    "\n",
    "There is a statistically significant difference in the average post blood pressure between males and females, t= 3.3480, p= 0.001.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce51cd75",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7b7029",
   "metadata": {},
   "source": [
    "###  Paired Samples t-test <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fc6a86",
   "metadata": {},
   "source": [
    "# Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d469892",
   "metadata": {},
   "source": [
    "Correlation is a statistical measure that describes the strength and direction of a relationship between two numerical variables. It helps in understanding how changes in one variable are associated with changes in another variable.\n",
    "\n",
    "- Types of Correlation:\n",
    "\n",
    "1. Pearson Correlation Coefficient (Pearson's r):\n",
    "    - Measures linear correlation between two continuous variables. Ranges from -1 to +1.\n",
    "    - +1 indicates a perfect positive linear relationship.\n",
    "    - -1 indicates a perfect negative linear relationship.\n",
    "    - 0 indicates no linear relationship.\n",
    "    - Assumes a linear relationship and normality of data.\n",
    "2. Spearman's Rank Correlation (Spearman's rho):\n",
    "    - Measures monotonic relationship between two variables.\n",
    "    - Based on the ranks of the data (ordinal relationship).\n",
    "    - Also ranges from -1 to +1.\n",
    "- Robust to outliers and non-linear relationships.\n",
    "\n",
    "3. Kendall's Tau:\n",
    "    - Measures ordinal association between two variables.\n",
    "S   - imilar to Spearman's correlation but focuses on concordant and discordant pairs of ranks.\n",
    "\n",
    "\n",
    "- Visualizing correlations can provide a clear understanding of the relationships between variables in a dataset. Heatmaps are commonly used to visualize correlation matrices, especially when dealing with multiple variables.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37c1ce7",
   "metadata": {},
   "source": [
    "### Toy example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff7256e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample dataset with numerical columns 'X' and 'Y'\n",
    "data = {'X': [1, 2, 3, 4, 5], 'Y': [2, 4, 6, 8, 10]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Calculate Pearson correlation coefficient\n",
    "pearson_corr = df['X'].corr(df['Y'])  # Pandas corr() function\n",
    "print(f\"Pearson's correlation coefficient: {pearson_corr:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34a003f",
   "metadata": {},
   "source": [
    "This code snippet demonstrates using Pandas' corr() function to calculate the Pearson correlation coefficient between two columns ('X' and 'Y') in a DataFrame.\n",
    "\n",
    "For Spearman and Kendall correlations, you can use `df.corr(method='spearman')` or `df.corr(method='kendall')` respectively, specifying the method parameter in the corr() function.\n",
    "\n",
    "Understanding correlations is essential for identifying relationships between variables in your data, helping in feature selection, and guiding further analysis or modeling decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8046d846",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Let's visualize the correlation between features:</b> Use heatmap!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943dd1b4",
   "metadata": {},
   "source": [
    ">In Pandas, the` corr()` method calculates the correlation matrix by default using the Pearson correlation coefficient. \n",
    "\n",
    "> the correlation matrix and the subsequent heatmap visualization consider only numeric variables, which can be used to explore relationships among continuous measurements in the Iris dataset or any other dataset with mixed data types. Adjust this code as needed for your specific dataset and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507b3e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Loading the Iris dataset from Seaborn\n",
    "iris = sns.load_dataset('iris')\n",
    "\n",
    "# Selecting only numeric columns for correlation calculation\n",
    "numeric_columns = iris.select_dtypes(include='number')\n",
    "\n",
    "# Calculating the correlation matrix\n",
    "corr_matrix = numeric_columns.corr()\n",
    "print(corr_matrix)\n",
    "\n",
    "# Plotting a heatmap of the correlation matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f', annot_kws={\"size\": 10})\n",
    "plt.title('Correlation Heatmap of Iris Dataset ')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
